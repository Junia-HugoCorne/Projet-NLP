# Projet-NLP

# Inspiration et Évolution du Projet

## Contexte et Inspiration
Le projet s'inspire de la compétition [Jigsaw Toxic Comment Classification Challenge](https://www.kaggle.com/search?q=jigsaw+toxic+comment+classification+challenge) sur Kaggle, qui propose un cadre riche pour explorer la classification des commentaires toxiques.

## Évolution du Modèle

### 1. Phase Baseline
- **Objectif :** Mettre en place une référence rapide et simple.
- **Approche :** Utilisation de techniques classiques de machine learning (régression logistique, SVM) pour une première analyse des données.
- **Résultat :** Un modèle baseline servant de point de comparaison pour les améliorations ultérieures.

### 2. Passage au Deep Learning
- **Objectif :** Capturer les nuances et le contexte des textes.
- **Approche :** Implémentation d'architectures de deep learning (RNN, LSTM) permettant une meilleure modélisation des séquences textuelles.
- **Résultat :** Une amélioration significative par rapport à la baseline grâce à une compréhension contextuelle renforcée.

### 3. Modèle Final Performant
- **Objectif :** Optimiser la précision et la robustesse du modèle.
- **Approche :** Adoption d'architectures avancées telles que les Transformers (ex. BERT) et fine-tuning sur des jeux de données spécifiques.
- **Optimisations :** Ajustement des hyperparamètres et validation croisée pour maximiser la performance.
- **Résultat :** Un modèle final performant et robuste pour la classification des commentaires toxiques.

## Conclusion
L'évolution de notre approche, de la mise en place d'une baseline simple à l'intégration de techniques avancées de deep learning, illustre notre capacité à itérer et améliorer continuellement notre modèle. Chaque étape, en commençant par le notebook initial, a permis d'apporter des améliorations significatives pour aboutir à un modèle final optimal.
